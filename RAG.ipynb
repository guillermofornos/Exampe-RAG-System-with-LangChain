{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (0.2.15)\n",
      "Requirement already satisfied: openai in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (1.43.0)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (0.2.15)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.7.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (2.0.32)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.35 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (0.2.37)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (0.1.108)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Using cached regex-2024.7.24-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.6)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.35->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.35->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\andre\\documents\\mlpills\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Using cached tiktoken-0.7.0-cp311-cp311-win_amd64.whl (799 kB)\n",
      "Using cached regex-2024.7.24-cp311-cp311-win_amd64.whl (269 kB)\n",
      "Installing collected packages: regex, tiktoken\n",
      "Successfully installed regex-2024.7.24 tiktoken-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai faiss-cpu python-dotenv langchain-community tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv \n",
    "import os \n",
    "\n",
    "load_dotenv() \n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Document preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "# Load text files from a directory\n",
    "loader = DirectoryLoader('./data', glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "documents = loader.load()\n",
    "\n",
    "# Process the documents\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Indexing Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Initialize the embeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# Create the vector store\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# Save the vector store\n",
    "vectorstore.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting Up the Retrieval Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Load the saved index\n",
    "embeddings = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Set up the retriever\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating the Generative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Create the RetrievalQA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using the RAG System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We know the climate is changing because we observe various effects that indicate significant changes in the environment. These include:\n",
      "\n",
      "1. **Temperature Records**: Historical temperature data show a clear warming trend during the 20th century.\n",
      "2. **Melting Ice**: Ice sheets and glaciers are shrinking, and Arctic sea ice is disappearing.\n",
      "3. **Rising Sea Levels**: Sea levels are rising due to the melting ice and thermal expansion of seawater.\n",
      "4. **Changes in Seasonal Patterns**: Snow melts sooner in the spring, and plants are flowering earlier.\n",
      "5. **Animal Behavior**: Animals are moving to higher elevations and latitudes to find cooler conditions.\n",
      "6. **Extreme Weather Events**: There has been an increase in the frequency and intensity of droughts, floods, and wildfires.\n",
      "\n",
      "These observations align with predictions made by climate models, confirming that climate change is occurring.\n",
      "\n",
      "Sources:\n",
      "data\\1 How do we know climate change is happening.txt\n",
      "data\\3 Do we really only have 150 years of climate data How is that enough to tell us about centuries of change.txt\n",
      "data\\4 How do we know climate change is caused by humans.txt\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"How do we know the climate is changing?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(result['result'])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Fine-Tuning and Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change to GPT-4, increase temperature and change chain type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using a different chain type\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model_name=\"gpt-4\", temperature=0.2),\n",
    "    chain_type=\"map_reduce\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We know that climate change is happening because we see the effects everywhere. Ice sheets and glaciers are shrinking while sea levels are rising. Arctic sea ice is disappearing. In the spring, snow melts sooner and plants flower earlier. Animals are moving to higher elevations and latitudes to find cooler conditions. Droughts, floods and wildfires have all gotten more extreme. The ocean, which has absorbed 90 percent of the heat trapped by greenhouse gases, is warming up. Historical records stretching back to the 1880s show a clear warming trend during the 20th century.\n",
      "\n",
      "Sources:\n",
      "data\\1 How do we know climate change is happening.txt\n",
      "data\\3 Do we really only have 150 years of climate data How is that enough to tell us about centuries of change.txt\n",
      "data\\4 How do we know climate change is caused by humans.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"How do we know the climate is changing?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(result['result'])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Custom Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "I want 5 reasons in bullet points to answer clearly the question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Ocean Heat Absorption**: The ocean has absorbed 90% of the heat trapped by greenhouse gases, indicating significant warming that is not fully reflected in surface temperatures. Measurements show that every layer of the ocean is warming.\n",
      "\n",
      "- **Observable Effects**: There are clear, observable effects of climate change, such as shrinking ice sheets and glaciers, rising sea levels, and the disappearance of Arctic sea ice. These changes are consistent with predictions made by climate models.\n",
      "\n",
      "- **Shifts in Natural Patterns**: Changes in seasonal patterns, such as earlier snowmelt and earlier flowering of plants, as well as shifts in animal migration to cooler areas, demonstrate the impact of climate change on ecosystems.\n",
      "\n",
      "- **Increased Weather Extremes**: The frequency and intensity of extreme weather events, including droughts, floods, and wildfires, have increased, providing further evidence of a changing climate.\n",
      "\n",
      "- **Historical Temperature Records**: Instrumental temperature data collected since the 1880s shows a clear warming trend over the 20th century, supporting the conclusion that the climate is changing.\n",
      "\n",
      "Sources:\n",
      "data\\1 How do we know climate change is happening.txt\n",
      "data\\3 Do we really only have 150 years of climate data How is that enough to tell us about centuries of change.txt\n",
      "data\\4 How do we know climate change is caused by humans.txt\n"
     ]
    }
   ],
   "source": [
    "query = \"How do we know the climate is changing?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(result['result'])\n",
    "print(\"\\nSources:\")\n",
    "for doc in result['source_documents']:\n",
    "    print(doc.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
